{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformaciones de Variables (Core)\n",
    "Descripción\n",
    "Ingeniería de Características: Transformaciones de Variables (Core)\n",
    "\n",
    " Descripción:\n",
    "\n",
    "En esta actividad, aplicarás diversas técnicas de transformación de variables para mejorar la calidad de los datos en el dataset «House Prices – Advanced Regression Techniques» disponible en Kaggle. Aprenderás a realizar transformaciones logarítmicas, escalado y creación de variables polinómicas para mejorar el rendimiento de los modelos predictivos.\n",
    "\n",
    "Enlace al dataset: https://www.kaggle.com/c/house-prices-advanced-regression-techniques\n",
    "\n",
    "\n",
    "\n",
    "Objetivo:\n",
    "\n",
    "El objetivo es realizar transformaciones de las variables en el dataset para mejorar la distribución de los datos y su relación con la variable objetivo (el precio de las casas). Estas transformaciones son clave para mejorar la precisión de los modelos de regresión y reducir sesgos en los datos.\n",
    "\n",
    "\n",
    "\n",
    "Instrucciones:\n",
    "\n",
    "1. Carga de datos:\n",
    "- Descarga el dataset «House Prices» de Kaggle. Realiza una exploración inicial de las variables numéricas y categóricas, prestando especial atención a aquellas que están relacionadas con el tamaño de la casa, el número de habitaciones y la calidad general.\n",
    "- Revisa la distribución de la variable objetivo (precio de la casa) y observa si tiene algún sesgo.\n",
    "\n",
    "2. Exploración y preprocesamiento de datos:\n",
    "- Antes de aplicar las transformaciones, realiza un análisis de las variables con distribuciones asimétricas o que contengan outliers. Estos son buenos candidatos para transformaciones logarítmicas o polinómicas.\n",
    "- También identifica variables que estén en escalas diferentes para aplicar técnicas de normalización o estandarización.\n",
    "\n",
    "3. Transformaciones de variables:\n",
    "- Aplica transformaciones logarítmicas a variables sesgadas como el «SalePrice» y otras variables numéricas que tengan una distribución sesgada.\n",
    "- Crea variables polinómicas a partir de las variables numéricas, como el tamaño total de la casa. Por ej}emplo, agrega el cuadrado o el cubo de estas variables como nuevas características para capturar posibles relaciones no lineales.\n",
    "- Estandariza las variables numéricas para que todas tengan la misma escala, lo cual es útil cuando se entrenan modelos de regresión o algoritmos basados en distancia como KNN.\n",
    "\n",
    "4. Evaluación de las transformaciones:\n",
    "- Aplica un modelo de regresión antes y después de las transformaciones para evaluar su impacto en el rendimiento del modelo.\n",
    "- Compara métricas como el RMSE (Root Mean Squared Error) y el R-squared para ver si las transformaciones logarítmicas y polinómicas han mejorado la predicción del precio de las casas.\n",
    "\n",
    "5. Interpretación de los resultados:\n",
    "- Analiza cuáles de las transformaciones aplicadas tuvieron un mayor impacto en la mejora del modelo. Discute cómo las transformaciones logarítmicas ayudan a manejar el sesgo en los datos y cómo las variables polinómicas capturan relaciones más complejas.\n",
    "- Reflexiona sobre la importancia de transformar variables antes de aplicar modelos de machine learning.\n",
    "\n",
    "\n",
    "\n",
    "Análisis de Resultados:\n",
    "\n",
    "- El análisis debe centrarse en cómo las diferentes transformaciones afectaron la distribución de las variables y cómo esto influyó en la precisión del modelo predictivo. Discute las ventajas y desventajas de las transformaciones aplicadas y su relevancia en problemas de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
      "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
      "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
      "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
      "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
      "\n",
      "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
      "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
      "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
      "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
      "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
      "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
      "\n",
      "  YrSold  SaleType  SaleCondition  SalePrice  \n",
      "0   2008        WD         Normal     208500  \n",
      "1   2007        WD         Normal     181500  \n",
      "2   2008        WD         Normal     223500  \n",
      "3   2006        WD        Abnorml     140000  \n",
      "4   2008        WD         Normal     250000  \n",
      "\n",
      "[5 rows x 81 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/mathiorti/Desktop/Me/Cursos/Data Analisis and Machine Learning/Data Sets/train_house_prices.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables candidatas para transformaciones:\n",
      "                Skewness  Outliers\n",
      "MSSubClass      1.407657       103\n",
      "LotFrontage     2.163569        88\n",
      "LotArea        12.207688        69\n",
      "OverallQual     0.216944         2\n",
      "OverallCond     0.693067       125\n",
      "YearBuilt      -0.613461         7\n",
      "MasVnrArea      2.669084        96\n",
      "BsmtFinSF1      1.685503         7\n",
      "BsmtFinSF2      4.255261       167\n",
      "BsmtUnfSF       0.920268        29\n",
      "TotalBsmtSF     1.524255        61\n",
      "1stFlrSF        1.376757        20\n",
      "2ndFlrSF        0.813030         2\n",
      "LowQualFinSF    9.011341        26\n",
      "GrLivArea       1.366560        31\n",
      "BsmtFullBath    0.596067         1\n",
      "BsmtHalfBath    4.103403        82\n",
      "BedroomAbvGr    0.211790        35\n",
      "KitchenAbvGr    4.488397        68\n",
      "TotRmsAbvGrd    0.676341        30\n",
      "Fireplaces      0.649565         5\n",
      "GarageCars     -0.342549         5\n",
      "GarageArea      0.179981        21\n",
      "WoodDeckSF      1.541376        32\n",
      "OpenPorchSF     2.364342        77\n",
      "EnclosedPorch   3.089872       208\n",
      "3SsnPorch      10.304342        24\n",
      "ScreenPorch     4.122214       116\n",
      "PoolArea       14.828374         7\n",
      "MiscVal        24.476794        52\n",
      "SalePrice       1.882876        61\n"
     ]
    }
   ],
   "source": [
    "#Como son muchas columnas no puedo ir visualizando 1 por uno\n",
    "#Puedo hacer uso de Skewness que es una medida de la asimetria de una distribucion\n",
    "#Puedo identificar los outliers con el rango intercuartilico (IQR)\n",
    "\n",
    "numeric_features = df.select_dtypes(include=['number'])\n",
    "\n",
    "skewness = numeric_features.apply(lambda x: x.skew()) #Forma de calcular las asimetrias\n",
    "\n",
    "#Función para calcular los outliers\n",
    "def calculate_outliers(x):\n",
    "    Q1 = x.quantile(0.25)\n",
    "    Q3 = x.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return len(x[(x < lower_bound) | (x > upper_bound)])\n",
    "\n",
    "outliers = numeric_features.apply(calculate_outliers)\n",
    "\n",
    "#Combino skewness y outliers en un DataFrame\n",
    "analysis = pd.DataFrame({'Skewness': skewness, 'Outliers': outliers})\n",
    "\n",
    "#Lo que haré ahora es filtrar los que son relevantes\n",
    "candidates = analysis[(analysis['Skewness'].abs() > 1) | (analysis['Outliers'] > 0)]\n",
    "\n",
    "#Imprimo esto\n",
    "print('Variables candidatas para transformaciones:')\n",
    "print(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Variables a transformar\n",
    "log_transform_vars = [\n",
    "    'MSSubClass', 'LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1',\n",
    "    'BsmtFinSF2', 'TotalBsmtSF', '1stFlrSF', 'LowQualFinSF', 'GrLivArea',\n",
    "    'BsmtHalfBath', 'KitchenAbvGr', 'WoodDeckSF', 'OpenPorchSF',\n",
    "    'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'SalePrice'\n",
    "]\n",
    "\n",
    "# Aplico la transformación logarítmica\n",
    "for col in log_transform_vars:\n",
    "    if col in df.columns:\n",
    "        df[col] = np.log1p(df[col])  # Logaritmo natural log(x + 1), asegura que no haya problemas con 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  MSSubClass MSZoning  LotFrontage   LotArea Street Alley LotShape  \\\n",
      "0   1    4.110874       RL     4.189655  9.042040   Pave   NaN      Reg   \n",
      "1   2    3.044522       RL     4.394449  9.169623   Pave   NaN      Reg   \n",
      "2   3    4.110874       RL     4.234107  9.328212   Pave   NaN      IR1   \n",
      "3   4    4.262680       RL     4.110874  9.164401   Pave   NaN      IR1   \n",
      "4   5    4.110874       RL     4.442651  9.565284   Pave   NaN      IR1   \n",
      "\n",
      "  LandContour Utilities  ... MiscVal SalePrice  MoSold^2 MoSold YrSold  \\\n",
      "0         Lvl    AllPub  ...         -0.106682  2.557156     -0.221921   \n",
      "1         Lvl    AllPub  ...         -0.040527  0.239229      0.300528   \n",
      "2         Lvl    AllPub  ...         -0.139822  0.981866      0.137513   \n",
      "3         Lvl    AllPub  ...          0.083313  2.557156      2.187032   \n",
      "4         Lvl    AllPub  ...         -0.193272  4.413749      0.291557   \n",
      "\n",
      "  MoSold SalePrice  YrSold^2 YrSold SalePrice SalePrice^2      TotalSF  \\\n",
      "0        -0.895609  0.019259         0.077725    0.313675   867.506876   \n",
      "1        -0.104065  0.377535        -0.130730    0.045268    14.282490   \n",
      "2         0.727360  0.019259         0.101869    0.538824   879.650920   \n",
      "3         0.699424  1.870479         0.598189    0.191304   769.498378   \n",
      "4         2.131673  0.019259         0.140811    1.029517  1067.088066   \n",
      "\n",
      "   Ratio_LotArea_GrLivArea  Product_Bedroom_Bathroom  \n",
      "0                 1.214539                         6  \n",
      "1                 1.284037                         6  \n",
      "2                 1.245706                         6  \n",
      "3                 1.230300                         3  \n",
      "4                 1.242929                         8  \n",
      "\n",
      "[5 rows x 863 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "\n",
    "# Identificar solo las columnas numéricas\n",
    "num_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Preprocesamiento para datos numéricos\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Imputación de valores faltantes\n",
    "    ('scaler', StandardScaler())  # Escalado estándar\n",
    "])\n",
    "\n",
    "# Ahora hago el preprocesamiento solo para las columnas numéricas\n",
    "data_processed = numeric_transformer.fit_transform(df[num_columns])\n",
    "\n",
    "# Generar características polinómicas\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "# Aplico PolynomialFeatures a las columnas numéricas procesadas\n",
    "data_poly = poly.fit_transform(data_processed)\n",
    "\n",
    "# Convertir a DataFrame con nombres de las nuevas características\n",
    "poly_feature_names = poly.get_feature_names_out(num_columns)\n",
    "data_poly_df = pd.DataFrame(data_poly, columns=poly_feature_names)\n",
    "\n",
    "# Agregar características polinómicas al DataFrame original\n",
    "data_final = pd.concat([df.reset_index(drop=True), data_poly_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Agregar características combinadas adicionales\n",
    "data_final['TotalSF'] = df['1stFlrSF'] + df['2ndFlrSF'] + df['TotalBsmtSF']  # Tamaño total de la casa\n",
    "data_final['Ratio_LotArea_GrLivArea'] = df['LotArea'] / df['GrLivArea']  # Relación entre área del terreno y área habitable\n",
    "data_final['Product_Bedroom_Bathroom'] = df['BedroomAbvGr'] * df['FullBath']  # Interacción entre habitaciones y baños\n",
    "\n",
    "# Verificar el resultado\n",
    "print(data_final.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Elimino las columnas duplicadas\n",
    "data_final = data_final.loc[:, ~data_final.columns.duplicated()]\n",
    "\n",
    "# Selecciono la variable objetivo y la separo\n",
    "X = data_final.drop('SalePrice', axis=1)  # Seleccionar todas las columnas excepto SalePrice\n",
    "y = data_final['SalePrice']  # Columna objetivo\n",
    "\n",
    "# Divido los conjuntos de entrenamiento y de prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Identifico las columnas categoricas y numéricas\n",
    "num_columns = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "cat_columns = X.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "# Preprocesadores para columnas numéricas y categóricas\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "#Pipeline completo\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_columns),\n",
    "        ('cat', categorical_transformer, cat_columns)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2.173828541934324\n",
      "R^2 Score: -10.648984651818619\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Creo el pipeline completo con regresión lineal\n",
    "pipeline_LR = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),  # Llamar al preprocesador definido arriba\n",
    "    ('regressor', LinearRegression())  # Modelo de regresión lineal\n",
    "])\n",
    "\n",
    "# Entreno el modelo\n",
    "pipeline_LR.fit(X_train, y_train)\n",
    "\n",
    "# Hago las predicciones\n",
    "y_pred_LR = pipeline_LR.predict(X_test)\n",
    "\n",
    "# Evaluación del modelo\n",
    "mse = mean_squared_error(y_test, y_pred_LR)\n",
    "r2 = r2_score(y_test, y_pred_LR)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 868875243.3319571\n",
      "R^2 Score: 0.8867225174181226\n"
     ]
    }
   ],
   "source": [
    "#Ahora hago sin todo el arreglo que para ver si hay alguna diferencia\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "data2 = pd.read_csv('/Users/mathiorti/Desktop/Me/Cursos/Data Analisis and Machine Learning/Data Sets/train_house_prices.csv')\n",
    "\n",
    "# Selecciono la variable objetivo y la separo\n",
    "X = data2.drop('SalePrice', axis=1)  # Seleccionar todas las columnas excepto SalePrice\n",
    "y = data2['SalePrice']  # Columna objetivo\n",
    "\n",
    "# Divido los conjuntos de entrenamiento y de prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Identifico las columnas categoricas y numéricas\n",
    "num_columns = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "cat_columns = X.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "# Preprocesadores para columnas numéricas y categóricas\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "#Pipeline completo\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_columns),\n",
    "        ('cat', categorical_transformer, cat_columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Creo el pipeline completo con regresión lineal\n",
    "pipeline_LR = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),  # Llamar al preprocesador definido arriba\n",
    "    ('regressor', LinearRegression())  # Modelo de regresión lineal\n",
    "])\n",
    "\n",
    "# Entreno el modelo\n",
    "pipeline_LR.fit(X_train, y_train)\n",
    "\n",
    "# Hago las predicciones\n",
    "y_pred_LR = pipeline_LR.predict(X_test)\n",
    "\n",
    "# Evaluación del modelo\n",
    "mse = mean_squared_error(y_test, y_pred_LR)\n",
    "r2 = r2_score(y_test, y_pred_LR)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo que puedo observar es que en este caso obtengo mejores resultados sin modificar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
