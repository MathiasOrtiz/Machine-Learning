{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducción de dimensionalidad / Ingeniería de Características: Creación de Nuevas Variables (Core)\n",
    "Descripción\n",
    "Ingeniería de Características: Creación de Nuevas Variables (Core)\n",
    "\n",
    "Descripción:\n",
    "\n",
    "En esta actividad, trabajarás con el dataset «Titanic – Machine Learning from Disaster» disponible en Kaggle para realizar ingeniería de características. El objetivo es crear nuevas variables a partir de las existentes y evaluar cómo estas nuevas características pueden mejorar la capacidad predictiva de un modelo de machine learning.\n",
    "\n",
    "Enlace al dataset: https://www.kaggle.com/c/titanic\n",
    "\n",
    "Objetivo:\n",
    "\n",
    "El objetivo principal es desarrollar habilidades en la creación de nuevas variables que capturen información útil no presente en las variables originales. Estas nuevas características serán utilizadas para mejorar el rendimiento de un modelo de clasificación que prediga la supervivencia de los pasajeros del Titanic.\n",
    "\n",
    "\n",
    "Instrucciones:\n",
    "\n",
    "1. Carga de datos:\n",
    "- Descarga y carga el dataset «Titanic» desde Kaggle. Realiza una exploración inicial de las variables disponibles, que incluyen información sobre la edad, el género, la clase del pasajero, entre otros.\n",
    "- Examina cuántos valores faltan en las variables importantes como la edad y el precio del boleto.\n",
    "\n",
    "2. Exploración y preprocesamiento de datos:\n",
    "- Realiza una limpieza de los datos, manejando los valores nulos. Por ejemplo, puedes imputar los valores faltantes de la edad con la mediana o la media según sea conveniente.\n",
    "- Revisa la distribución de las variables y asegúrate de que las categorías estén codificadas correctamente para el modelado.\n",
    "\n",
    "3. Creación de nuevas características:\n",
    "- Crea nuevas variables a partir de las existentes. Algunas ideas incluyen:\n",
    "- Tamaño de la familia: Combina las variables «SibSp» (número de hermanos/esposos) y «Parch» (número de padres/hijos) para crear una variable que represente el tamaño total de la familia del pasajero.\n",
    "- Cabina desconocida: Crea una variable binaria que indique si la cabina de un pasajero es conocida o no, lo cual podría estar relacionado con la clase o la ubicación a bordo.\n",
    "- Categoría de tarifa: Agrupa la variable «Fare» en diferentes rangos para crear una variable categórica que represente el nivel de costo del boleto.\n",
    "- Título del pasajero: Extrae el título de cada pasajero desde la variable «Name» y crea una nueva variable categórica que represente estos títulos (e.g., Mr., Mrs., Miss.).\n",
    "\n",
    "4. Evaluación de nuevas características:\n",
    "- Aplica un modelo de machine learning (como un modelo de regresión logística o un árbol de decisión) antes y después de agregar las nuevas características para evaluar su impacto en el rendimiento del modelo.\n",
    "- Utiliza métricas como la exactitud y el F1-score para comparar el rendimiento con y sin las nuevas variables.\n",
    "\n",
    "5. Interpretación de los resultados:\n",
    "- Analiza cuáles de las nuevas características tuvieron el mayor impacto en el rendimiento del modelo. ¿Cómo ayudaron a mejorar la capacidad predictiva del modelo en comparación con las variables originales?\n",
    "- Discute cómo las nuevas características creadas representan una mejor captura de la información sobre los pasajeros.\n",
    "\n",
    "\n",
    "Análisis de Resultados:\n",
    "\n",
    "- El análisis debe centrarse en la importancia de las nuevas variables y su capacidad para mejorar la predicción de la supervivencia en el Titanic. Discute los beneficios de realizar ingeniería de características y cómo estas nuevas variables pueden capturar información latente en los datos originales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/mathiorti/Desktop/Me/Cursos/Data Analisis and Machine Learning/Data Sets/train.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Faltan 177 en la edad. Ninguno en el precio del boleto.\n",
    "#Haré un preprocesamiento luego con un pipeline\n",
    "\n",
    "df['FamilySize'] = df['SibSp'] + df['Parch'] +1 #El +1 es para incluir al pasajero\n",
    "df['CabinKnow'] = df['Cabin'].notna().astype(int) #Si se conoce la cabina 1 y si no 0.\n",
    "df['FareCategory'] = df['Fare'].apply(lambda x: 'Low' if x <= 7.91 else 'Medium' if x <= 14.454 else 'High')\n",
    "df['Title'] = df['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hago el preprocesamiento\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#Selecciono la variable objetivo y la separo\n",
    "X = df.drop(['Survived'], axis = 1)\n",
    "y = df['Survived'] #Esta sería mi columna objetivo\n",
    "\n",
    "num_columns = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "cat_columns = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps =[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore') )\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_columns),\n",
    "        ('cat', categorical_transformer, cat_columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "#Ahora hago el pipeline completo\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte del modelo Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.85       105\n",
      "           1       0.79      0.80      0.79        74\n",
      "\n",
      "    accuracy                           0.83       179\n",
      "   macro avg       0.82      0.82      0.82       179\n",
      "weighted avg       0.83      0.83      0.83       179\n",
      "\n",
      "Accuracy del modelo Logistic Regression: 0.8268156424581006\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "#Divido los datos\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Creo el modelo\n",
    "pipeline_LR = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor), #Con esto llamo al preprocesamiento hecho más arriba\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "#Entreno el modelo\n",
    "pipeline_LR.fit(X_train, y_train)\n",
    "\n",
    "#Hago las predicciones\n",
    "y_pred_LR = pipeline_LR.predict(X_test)\n",
    "\n",
    "#Evaluo el modelo\n",
    "print(f'Reporte del modelo Logistic Regression:')\n",
    "print(classification_report(y_test, y_pred_LR))\n",
    "\n",
    "#Veo su accuracy \n",
    "accuracy_LR = accuracy_score(y_test, y_pred_LR)\n",
    "\n",
    "print(f'Accuracy del modelo Logistic Regression: {accuracy_LR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "#Ne da un accuracy de 0.83 una vez agregadas las variables nuevas.\n",
    "#Ahora probaré cuanto dará sin esas variables\n",
    "# Hago el preprocesamiento\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#Con esto vuelvo a cargar el dataset para que esté sin las variables nuevas\n",
    "df = pd.read_csv('/Users/mathiorti/Desktop/Me/Cursos/Data Analisis and Machine Learning/Data Sets/train.csv')\n",
    "\n",
    "#Selecciono la variable objetivo y la separo\n",
    "X = df.drop(['Survived'], axis = 1)\n",
    "y = df['Survived'] #Esta sería mi columna objetivo\n",
    "\n",
    "num_columns = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "cat_columns = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps =[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore') )\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_columns),\n",
    "        ('cat', categorical_transformer, cat_columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "#Ahora hago el pipeline completo\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte del modelo Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85       105\n",
      "           1       0.81      0.74      0.77        74\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.82      0.81      0.81       179\n",
      "weighted avg       0.82      0.82      0.82       179\n",
      "\n",
      "Accuracy del modelo Logistic Regression: 0.8212290502793296\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "#Divido los datos\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Creo el modelo\n",
    "pipeline_LR = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor), #Con esto llamo al preprocesamiento hecho más arriba\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "#Entreno el modelo\n",
    "pipeline_LR.fit(X_train, y_train)\n",
    "\n",
    "#Hago las predicciones\n",
    "y_pred_LR = pipeline_LR.predict(X_test)\n",
    "\n",
    "#Evaluo el modelo\n",
    "print(f'Reporte del modelo Logistic Regression:')\n",
    "print(classification_report(y_test, y_pred_LR))\n",
    "\n",
    "#Veo su accuracy \n",
    "accuracy_LR = accuracy_score(y_test, y_pred_LR)\n",
    "\n",
    "print(f'Accuracy del modelo Logistic Regression: {accuracy_LR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veo como me da un accuracy de 0.82 o sea de 82 %\n",
    "#Puedo decir que mejora el accuracy. La clase 1 (sobrevivientes) mejora de 77 a 79%\n",
    "#Hay mayor equilibrio entre las clases 0 y 1\n",
    "#Puedo decir que las nuevas variables contribuyen a mejorar el modelo ligeramente."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
